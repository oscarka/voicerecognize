#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Whisper + Pyannote å®Œæ•´å®ç°
"""

import whisper
import torch
from pyannote.audio import Pipeline
from pyannote.audio.pipelines.utils.hook import ProgressHook
import json
import os

def setup_pyannote():
    """è®¾ç½®Pyannote"""
    # éœ€è¦ä»HuggingFaceè·å–è®¿é—®ä»¤ç‰Œ
    # https://huggingface.co/pyannote/speaker-diarization
    pipeline = Pipeline.from_pretrained(
        "pyannote/speaker-diarization",
        use_auth_token="YOUR_HF_TOKEN"
    )
    return pipeline

def diarize_audio(audio_path, pipeline):
    """è¯´è¯äººåˆ†ç¦»"""
    print("ğŸ¯ å¼€å§‹è¯´è¯äººåˆ†ç¦»...")
    
    with ProgressHook() as hook:
        diarization = pipeline(audio_path, hook=hook)
    
    return diarization

def transcribe_segments(audio_path, diarization, model_name="small"):
    """è½¬å½•éŸ³é¢‘ç‰‡æ®µ"""
    print("ğŸ“ å¼€å§‹è¯­éŸ³è½¬å½•...")
    
    # åŠ è½½Whisperæ¨¡å‹
    model = whisper.load_model(model_name)
    
    results = []
    
    # ä¸ºæ¯ä¸ªè¯´è¯äººç‰‡æ®µè¿›è¡Œè½¬å½•
    for turn, _, speaker in diarization.itertracks(yield_label=True):
        start_time = turn.start
        end_time = turn.end
        
        # æå–éŸ³é¢‘ç‰‡æ®µ
        # è¿™é‡Œéœ€è¦å®ç°éŸ³é¢‘ç‰‡æ®µæå–é€»è¾‘
        
        # è½¬å½•
        result = model.transcribe(audio_path, start=start_time, end=end_time)
        
        results.append({
            "speaker": speaker,
            "start": start_time,
            "end": end_time,
            "text": result["text"].strip()
        })
    
    return results

def main():
    """ä¸»å‡½æ•°"""
    audio_file = "ba84462e-fdee-42fe-9439-86808b3d3212.wav"
    
    if not os.path.exists(audio_file):
        print(f"âŒ éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_file}")
        return
    
    print("ğŸš€ Whisper + Pyannote å®Œæ•´æµç¨‹")
    print("=" * 50)
    
    # 1. è®¾ç½®Pyannote
    try:
        pipeline = setup_pyannote()
        print("âœ… Pyannoteè®¾ç½®å®Œæˆ")
    except Exception as e:
        print(f"âŒ Pyannoteè®¾ç½®å¤±è´¥: {e}")
        print("ğŸ’¡ éœ€è¦ä»HuggingFaceè·å–è®¿é—®ä»¤ç‰Œ")
        return
    
    # 2. è¯´è¯äººåˆ†ç¦»
    try:
        diarization = diarize_audio(audio_file, pipeline)
        print("âœ… è¯´è¯äººåˆ†ç¦»å®Œæˆ")
    except Exception as e:
        print(f"âŒ è¯´è¯äººåˆ†ç¦»å¤±è´¥: {e}")
        return
    
    # 3. è½¬å½•
    try:
        results = transcribe_segments(audio_file, diarization)
        print("âœ… è½¬å½•å®Œæˆ")
    except Exception as e:
        print(f"âŒ è½¬å½•å¤±è´¥: {e}")
        return
    
    # 4. ä¿å­˜ç»“æœ
    output_file = "whisper_pyannote_complete.txt"
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write("=== Whisper + Pyannote å®Œæ•´è½¬å½•ç»“æœ ===\n\n")
        
        for result in results:
            f.write(f"[{result['start']:.1f}s - {result['end']:.1f}s] {result['speaker']}: {result['text']}\n")
    
    print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {output_file}")

if __name__ == "__main__":
    main()
