#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Whisper + Pyannote å¿«é€Ÿæµ‹è¯•
åªå¤„ç†éŸ³é¢‘çš„å‰2åˆ†é’Ÿæ¥å¿«é€Ÿå±•ç¤ºæ•ˆæœ
"""
import os
import sys
import time
import json
import subprocess
from pathlib import Path
import whisper
from pyannote.audio import Pipeline

def create_short_audio(input_file, output_file, duration=120):
    """åˆ›å»ºçŸ­éŸ³é¢‘æ–‡ä»¶ç”¨äºå¿«é€Ÿæµ‹è¯•"""
    print(f"åˆ›å»º {duration}ç§’ çš„çŸ­éŸ³é¢‘æ–‡ä»¶...")
    
    cmd = [
        "ffmpeg", "-i", input_file,
        "-t", str(duration),  # åªå–å‰durationç§’
        "-c", "copy", output_file,
        "-y"
    ]
    
    try:
        subprocess.run(cmd, check=True, capture_output=True)
        print(f"âœ… çŸ­éŸ³é¢‘æ–‡ä»¶åˆ›å»ºæˆåŠŸ: {output_file}")
        return True
    except subprocess.CalledProcessError as e:
        print(f"âŒ åˆ›å»ºçŸ­éŸ³é¢‘æ–‡ä»¶å¤±è´¥: {e}")
        return False

def run_quick_test(audio_file):
    """è¿è¡Œå¿«é€Ÿæµ‹è¯•"""
    print(f"\n=== Whisper + Pyannote å¿«é€Ÿæµ‹è¯• ===")
    print(f"å¤„ç†éŸ³é¢‘: {audio_file}")
    
    # 1. åŠ è½½Whisperæ¨¡å‹
    print("\n1. åŠ è½½Whisperæ¨¡å‹...")
    start_time = time.time()
    whisper_model = whisper.load_model("small")
    whisper_load_time = time.time() - start_time
    print(f"   Whisperæ¨¡å‹åŠ è½½å®Œæˆï¼Œè€—æ—¶: {whisper_load_time:.2f}ç§’")
    
    # 2. åˆå§‹åŒ–Pyannote Pipeline
    print("\n2. åˆå§‹åŒ–Pyannote Pipeline...")
    start_time = time.time()
    pipeline = Pipeline.from_pretrained(
        "pyannote/speaker-diarization-3.1",
        use_auth_token=os.getenv("HF_TOKEN")
    )
    pyannote_load_time = time.time() - start_time
    print(f"   Pyannote PipelineåŠ è½½å®Œæˆï¼Œè€—æ—¶: {pyannote_load_time:.2f}ç§’")
    
    # 3. æ‰§è¡Œè¯´è¯äººåˆ†ç¦»
    print("\n3. æ‰§è¡Œè¯´è¯äººåˆ†ç¦»...")
    start_time = time.time()
    diarization = pipeline(audio_file)
    diarization_time = time.time() - start_time
    print(f"   è¯´è¯äººåˆ†ç¦»å®Œæˆï¼Œè€—æ—¶: {diarization_time:.2f}ç§’")
    
    # 4. åˆ†æè¯´è¯äººåˆ†ç¦»ç»“æœ
    print("\n4. åˆ†æè¯´è¯äººåˆ†ç¦»ç»“æœ...")
    speakers = set()
    segments = []
    
    for turn, _, speaker in diarization.itertracks(yield_label=True):
        speakers.add(speaker)
        segments.append({
            'start': turn.start,
            'end': turn.end,
            'speaker': speaker
        })
    
    print(f"   æ£€æµ‹åˆ° {len(speakers)} ä¸ªè¯´è¯äºº: {list(speakers)}")
    print(f"   æ€»å…± {len(segments)} ä¸ªè¯­éŸ³ç‰‡æ®µ")
    
    # 5. å¯¹æ¯ä¸ªç‰‡æ®µè¿›è¡Œè½¬å½•
    print("\n5. å¯¹æ¯ä¸ªç‰‡æ®µè¿›è¡Œè½¬å½•...")
    transcription_results = []
    total_transcribe_time = 0
    
    for i, segment in enumerate(segments):
        print(f"   å¤„ç†ç‰‡æ®µ {i+1}/{len(segments)}: {segment['start']:.1f}s - {segment['end']:.1f}s ({segment['speaker']})")
        
        # ä½¿ç”¨ffmpegæå–éŸ³é¢‘ç‰‡æ®µ
        segment_file = f"temp_segment_{i}.wav"
        
        # æå–éŸ³é¢‘ç‰‡æ®µ
        cmd = [
            "ffmpeg", "-i", audio_file,
            "-ss", str(segment['start']),
            "-t", str(segment['end'] - segment['start']),
            "-c", "copy", segment_file,
            "-y"
        ]
        
        try:
            subprocess.run(cmd, check=True, capture_output=True)
        except subprocess.CalledProcessError as e:
            print(f"   âš ï¸  ç‰‡æ®µ {i+1} æå–å¤±è´¥ï¼Œè·³è¿‡")
            continue
        
        # ä½¿ç”¨Whisperè½¬å½•
        transcribe_start = time.time()
        result = whisper_model.transcribe(segment_file, verbose=False)
        transcribe_time = time.time() - transcribe_start
        total_transcribe_time += transcribe_time
        
        # ä¿å­˜ç»“æœ
        transcription_results.append({
            'segment_id': i,
            'start': segment['start'],
            'end': segment['end'],
            'speaker': segment['speaker'],
            'text': result['text'].strip(),
            'transcribe_time': transcribe_time
        })
        
        print(f"     è½¬å½•å®Œæˆ: {result['text'].strip()}")
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if os.path.exists(segment_file):
            os.remove(segment_file)
    
    # 6. ç”Ÿæˆæœ€ç»ˆç»“æœ
    print("\n6. ç”Ÿæˆæœ€ç»ˆç»“æœ...")
    final_result = {
        'audio_file': audio_file,
        'total_speakers': len(speakers),
        'total_segments': len(segments),
        'whisper_model': 'small',
        'pyannote_model': 'pyannote/speaker-diarization-3.1',
        'processing_times': {
            'whisper_load': whisper_load_time,
            'pyannote_load': pyannote_load_time,
            'diarization': diarization_time,
            'total_transcription': total_transcribe_time
        },
        'transcriptions': transcription_results
    }
    
    return final_result

def save_results(result, output_file):
    """ä¿å­˜ç»“æœåˆ°æ–‡ä»¶"""
    print(f"\n=== ä¿å­˜ç»“æœåˆ°: {output_file} ===")
    
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write("=== Whisper + Pyannote å¿«é€Ÿæµ‹è¯•ç»“æœ ===\n\n")
        
        f.write(f"éŸ³é¢‘æ–‡ä»¶: {result['audio_file']}\n")
        f.write(f"è¯´è¯äººæ•°é‡: {result['total_speakers']}\n")
        f.write(f"è¯­éŸ³ç‰‡æ®µæ•°: {result['total_segments']}\n")
        f.write(f"Whisperæ¨¡å‹: {result['whisper_model']}\n")
        f.write(f"Pyannoteæ¨¡å‹: {result['pyannote_model']}\n\n")
        
        f.write("å¤„ç†æ—¶é—´:\n")
        for key, value in result['processing_times'].items():
            f.write(f"  {key}: {value:.2f}ç§’\n")
        f.write("\n")
        
        f.write("è½¬å½•ç»“æœ:\n")
        f.write("=" * 50 + "\n")
        
        for trans in result['transcriptions']:
            f.write(f"[{trans['start']:.1f}s - {trans['end']:.1f}s] {trans['speaker']}: {trans['text']}\n")
        
        f.write("\n" + "=" * 50 + "\n")
        f.write("JSONæ ¼å¼ç»“æœ:\n")
        f.write(json.dumps(result, ensure_ascii=False, indent=2))

def main():
    """ä¸»å‡½æ•°"""
    print("=== Whisper + Pyannote å¿«é€Ÿæµ‹è¯• ===")
    
    # æ£€æŸ¥HF_TOKEN
    hf_token = os.getenv("HF_TOKEN")
    if not hf_token or hf_token == "hf_xxx":
        print("âŒ è¯·è®¾ç½®æœ‰æ•ˆçš„HF_TOKENç¯å¢ƒå˜é‡")
        print("   è·å–åœ°å€: https://huggingface.co/settings/tokens")
        return
    
    # åŸå§‹éŸ³é¢‘æ–‡ä»¶
    original_audio = "ba84462e-fdee-42fe-9439-86808b3d3212.wav"
    short_audio = "short_test_audio.wav"
    
    if not os.path.exists(original_audio):
        print(f"\nâŒ éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {original_audio}")
        return
    
    # åˆ›å»ºçŸ­éŸ³é¢‘æ–‡ä»¶
    if not create_short_audio(original_audio, short_audio, 120):  # 2åˆ†é’Ÿ
        print("âŒ æ— æ³•åˆ›å»ºçŸ­éŸ³é¢‘æ–‡ä»¶")
        return
    
    # è¿è¡Œå¿«é€Ÿæµ‹è¯•
    try:
        result = run_quick_test(short_audio)
        
        # ä¿å­˜ç»“æœ
        output_file = "whisper_pyannote_quick_result.txt"
        save_results(result, output_file)
        
        print(f"\nâœ… å¿«é€Ÿæµ‹è¯•å®Œæˆï¼ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
        
        # æ˜¾ç¤ºç®€è¦ç»“æœ
        print("\n=== ç®€è¦ç»“æœé¢„è§ˆ ===")
        for trans in result['transcriptions'][:5]:  # åªæ˜¾ç¤ºå‰5ä¸ªç‰‡æ®µ
            print(f"[{trans['start']:.1f}s - {trans['end']:.1f}s] {trans['speaker']}: {trans['text']}")
        
        if len(result['transcriptions']) > 5:
            print(f"... è¿˜æœ‰ {len(result['transcriptions']) - 5} ä¸ªç‰‡æ®µ")
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if os.path.exists(short_audio):
            os.remove(short_audio)
            print(f"\nğŸ§¹ å·²æ¸…ç†ä¸´æ—¶æ–‡ä»¶: {short_audio}")
        
    except Exception as e:
        print(f"\nâŒ å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 