#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
WhisperåŠŸèƒ½æ¼”ç¤ºè„šæœ¬
å±•ç¤ºWhisperçš„åŸºæœ¬åŠŸèƒ½å’Œä½¿ç”¨æ–¹æ³•
"""

import whisper
import os
import time

def demo_whisper_basic():
    """æ¼”ç¤ºWhisperåŸºæœ¬åŠŸèƒ½"""
    print("ğŸ¤ WhisperåŠŸèƒ½æ¼”ç¤º")
    print("=" * 50)
    
    # 1. æ˜¾ç¤ºå¯ç”¨æ¨¡å‹
    print("ğŸ“‹ å¯ç”¨æ¨¡å‹:")
    models = whisper.available_models()
    for model in models:
        print(f"  - {model}")
    
    # 2. åŠ è½½æ¨¡å‹
    print(f"\nğŸ”„ æ­£åœ¨åŠ è½½tinyæ¨¡å‹...")
    start_time = time.time()
    model = whisper.load_model("tiny")
    load_time = time.time() - start_time
    print(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆï¼Œè€—æ—¶: {load_time:.2f}ç§’")
    
    # 3. æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯
    print(f"\nğŸ“Š æ¨¡å‹ä¿¡æ¯:")
    print(f"  è®¾å¤‡: {model.device}")
    print(f"  æ¨¡å‹ç»´åº¦: {model.dims}")
    
    return model

def demo_transcription_with_sample():
    """æ¼”ç¤ºè½¬å½•åŠŸèƒ½ï¼ˆä½¿ç”¨ç¤ºä¾‹æ–‡æœ¬ï¼‰"""
    print("\nğŸµ è½¬å½•åŠŸèƒ½æ¼”ç¤º")
    print("-" * 30)
    
    # åˆ›å»ºä¸€ä¸ªç®€å•çš„æµ‹è¯•éŸ³é¢‘æ–‡ä»¶ï¼ˆä½¿ç”¨ç³»ç»Ÿå‘½ä»¤ç”Ÿæˆï¼‰
    test_audio = "test_audio.wav"
    
    # ä½¿ç”¨sayå‘½ä»¤ç”Ÿæˆæµ‹è¯•éŸ³é¢‘ï¼ˆmacOSç³»ç»Ÿå‘½ä»¤ï¼‰
    print("ğŸ”Š ç”Ÿæˆæµ‹è¯•éŸ³é¢‘...")
    os.system(f'say -o {test_audio} "Hello, this is a test of OpenAI Whisper speech recognition."')
    
    if os.path.exists(test_audio):
        print(f"âœ… æµ‹è¯•éŸ³é¢‘å·²ç”Ÿæˆ: {test_audio}")
        
        # åŠ è½½æ¨¡å‹
        model = whisper.load_model("tiny")
        
        # æ‰§è¡Œè½¬å½•
        print("ğŸ“ å¼€å§‹è½¬å½•...")
        start_time = time.time()
        result = model.transcribe(test_audio)
        transcribe_time = time.time() - start_time
        
        print(f"âœ… è½¬å½•å®Œæˆï¼Œè€—æ—¶: {transcribe_time:.2f}ç§’")
        print(f"ğŸ“‹ è½¬å½•ç»“æœ: {result['text']}")
        
        # æ¸…ç†æµ‹è¯•æ–‡ä»¶
        os.remove(test_audio)
        print("ğŸ§¹ æµ‹è¯•æ–‡ä»¶å·²æ¸…ç†")
        
        return result
    else:
        print("âŒ æ— æ³•ç”Ÿæˆæµ‹è¯•éŸ³é¢‘")
        return None

def demo_language_detection():
    """æ¼”ç¤ºè¯­è¨€æ£€æµ‹åŠŸèƒ½"""
    print("\nğŸŒ è¯­è¨€æ£€æµ‹åŠŸèƒ½æ¼”ç¤º")
    print("-" * 30)
    
    # åˆ›å»ºä¸­æ–‡æµ‹è¯•éŸ³é¢‘
    test_audio_cn = "test_audio_cn.wav"
    os.system(f'say -o {test_audio_cn} -v Ting-Ting "ä½ å¥½ï¼Œè¿™æ˜¯ä¸€ä¸ªè¯­éŸ³è¯†åˆ«æµ‹è¯•ã€‚"')
    
    if os.path.exists(test_audio_cn):
        model = whisper.load_model("tiny")
        
        # åŠ è½½éŸ³é¢‘
        audio = whisper.load_audio(test_audio_cn)
        audio = whisper.pad_or_trim(audio)
        mel = whisper.log_mel_spectrogram(audio).to(model.device)
        
        # æ£€æµ‹è¯­è¨€
        _, probs = model.detect_language(mel)
        detected_lang = max(probs, key=probs.get)
        
        print(f"ğŸ” æ£€æµ‹åˆ°çš„è¯­è¨€: {detected_lang}")
        print(f"ğŸ“Š è¯­è¨€æ¦‚ç‡åˆ†å¸ƒ:")
        for lang, prob in sorted(probs.items(), key=lambda x: x[1], reverse=True)[:5]:
            print(f"  {lang}: {prob:.3f}")
        
        # æ¸…ç†
        os.remove(test_audio_cn)
        return detected_lang
    else:
        print("âŒ æ— æ³•ç”Ÿæˆä¸­æ–‡æµ‹è¯•éŸ³é¢‘")
        return None

def demo_model_comparison():
    """æ¼”ç¤ºä¸åŒæ¨¡å‹çš„æ€§èƒ½å¯¹æ¯”"""
    print("\nâš¡ æ¨¡å‹æ€§èƒ½å¯¹æ¯”")
    print("-" * 30)
    
    # åˆ›å»ºæµ‹è¯•éŸ³é¢‘
    test_audio = "test_audio_compare.wav"
    os.system(f'say -o {test_audio} "This is a performance comparison test for different Whisper models."')
    
    if not os.path.exists(test_audio):
        print("âŒ æ— æ³•ç”Ÿæˆæµ‹è¯•éŸ³é¢‘")
        return
    
    models_to_test = ["tiny", "base", "small"]
    results = {}
    
    for model_name in models_to_test:
        print(f"\nğŸ”„ æµ‹è¯•æ¨¡å‹: {model_name}")
        
        # åŠ è½½æ¨¡å‹
        start_load = time.time()
        model = whisper.load_model(model_name)
        load_time = time.time() - start_load
        
        # è½¬å½•
        start_transcribe = time.time()
        result = model.transcribe(test_audio)
        transcribe_time = time.time() - start_transcribe
        
        results[model_name] = {
            "load_time": load_time,
            "transcribe_time": transcribe_time,
            "text": result["text"]
        }
        
        print(f"  åŠ è½½æ—¶é—´: {load_time:.2f}ç§’")
        print(f"  è½¬å½•æ—¶é—´: {transcribe_time:.2f}ç§’")
        print(f"  è½¬å½•ç»“æœ: {result['text']}")
    
    # æ¸…ç†
    os.remove(test_audio)
    
    # æ˜¾ç¤ºå¯¹æ¯”ç»“æœ
    print(f"\nğŸ“Š æ€§èƒ½å¯¹æ¯”æ€»ç»“:")
    print(f"{'æ¨¡å‹':<10} {'åŠ è½½æ—¶é—´':<12} {'è½¬å½•æ—¶é—´':<12} {'æ€»æ—¶é—´':<12}")
    print("-" * 50)
    for model_name, data in results.items():
        total_time = data["load_time"] + data["transcribe_time"]
        print(f"{model_name:<10} {data['load_time']:<12.2f} {data['transcribe_time']:<12.2f} {total_time:<12.2f}")

def main():
    """ä¸»æ¼”ç¤ºå‡½æ•°"""
    print("ğŸš€ OpenAI Whisper åŠŸèƒ½æ¼”ç¤º")
    print("=" * 60)
    
    try:
        # 1. åŸºæœ¬åŠŸèƒ½æ¼”ç¤º
        model = demo_whisper_basic()
        
        # 2. è½¬å½•åŠŸèƒ½æ¼”ç¤º
        demo_transcription_with_sample()
        
        # 3. è¯­è¨€æ£€æµ‹æ¼”ç¤º
        demo_language_detection()
        
        # 4. æ¨¡å‹æ€§èƒ½å¯¹æ¯”
        demo_model_comparison()
        
        print("\nğŸ‰ æ‰€æœ‰æ¼”ç¤ºå®Œæˆï¼")
        print("\nğŸ’¡ ä½¿ç”¨å»ºè®®:")
        print("  - å¼€å‘æµ‹è¯•: ä½¿ç”¨ tiny æˆ– base æ¨¡å‹")
        print("  - æ—¥å¸¸ä½¿ç”¨: ä½¿ç”¨ turbo æ¨¡å‹")
        print("  - é«˜è´¨é‡éœ€æ±‚: ä½¿ç”¨ large æ¨¡å‹")
        print("  - ä¸­æ–‡è¯†åˆ«: å»ºè®®ä½¿ç”¨ medium æˆ– large æ¨¡å‹")
        
    except Exception as e:
        print(f"âŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")

if __name__ == "__main__":
    main() 