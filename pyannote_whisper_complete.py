#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Pyannote + Whisper å®Œæ•´å®ç°
"""

import os
import whisper
import torch
from pyannote.audio import Pipeline
from pyannote.audio.pipelines.utils.hook import ProgressHook
import json
import time

def setup_pyannote():
    """è®¾ç½®Pyannote"""
    # éœ€è¦è®¾ç½®ç¯å¢ƒå˜é‡: export HF_TOKEN=your_token
    hf_token = os.getenv("HF_TOKEN")
    if not hf_token:
        raise ValueError("è¯·è®¾ç½®HF_TOKENç¯å¢ƒå˜é‡")
    
    print("ğŸ”„ åŠ è½½Pyannoteæ¨¡å‹...")
    pipeline = Pipeline.from_pretrained(
        "pyannote/speaker-diarization",
        use_auth_token=hf_token
    )
    return pipeline

def diarize_audio(audio_path, pipeline):
    """è¯´è¯äººåˆ†ç¦»"""
    print("ğŸ¯ å¼€å§‹è¯´è¯äººåˆ†ç¦»...")
    
    with ProgressHook() as hook:
        diarization = pipeline(audio_path, hook=hook)
    
    return diarization

def transcribe_with_whisper(audio_path, segments, model_name="small"):
    """ä½¿ç”¨Whisperè½¬å½•"""
    print(f"ğŸ“ ä½¿ç”¨Whisper {model_name}æ¨¡å‹è½¬å½•...")
    
    # åŠ è½½Whisperæ¨¡å‹
    model = whisper.load_model(model_name)
    
    results = []
    
    for i, segment in enumerate(segments):
        start_time = segment["start"]
        end_time = segment["end"]
        speaker = segment["speaker"]
        
        print(f"ğŸ”„ è½¬å½•ç‰‡æ®µ {i+1}/{len(segments)}: {start_time:.1f}s - {end_time:.1f}s")
        
        # è½¬å½•
        result = model.transcribe(
            audio_path,
            start=start_time,
            end=end_time,
            verbose=False
        )
        
        results.append({
            "speaker": speaker,
            "start": start_time,
            "end": end_time,
            "text": result["text"].strip()
        })
    
    return results

def main():
    """ä¸»å‡½æ•°"""
    audio_file = "ba84462e-fdee-42fe-9439-86808b3d3212.wav"
    
    if not os.path.exists(audio_file):
        print(f"âŒ éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_file}")
        return
    
    print("ğŸš€ Pyannote + Whisper å®Œæ•´æµç¨‹")
    print("=" * 50)
    
    # 1. è®¾ç½®Pyannote
    try:
        pipeline = setup_pyannote()
        print("âœ… Pyannoteæ¨¡å‹åŠ è½½å®Œæˆ")
    except Exception as e:
        print(f"âŒ Pyannoteè®¾ç½®å¤±è´¥: {e}")
        print("ğŸ’¡ è¯·è®¾ç½®HF_TOKENç¯å¢ƒå˜é‡")
        return
    
    # 2. è¯´è¯äººåˆ†ç¦»
    try:
        diarization = diarize_audio(audio_file, pipeline)
        print("âœ… è¯´è¯äººåˆ†ç¦»å®Œæˆ")
        
        # æå–ç‰‡æ®µä¿¡æ¯
        segments = []
        for turn, _, speaker in diarization.itertracks(yield_label=True):
            segments.append({
                "speaker": speaker,
                "start": turn.start,
                "end": turn.end
            })
        
        print(f"ğŸ“‹ è¯†åˆ«åˆ° {len(segments)} ä¸ªè¯´è¯ç‰‡æ®µ")
        
    except Exception as e:
        print(f"âŒ è¯´è¯äººåˆ†ç¦»å¤±è´¥: {e}")
        return
    
    # 3. è½¬å½•
    try:
        results = transcribe_with_whisper(audio_file, segments, "small")
        print("âœ… è½¬å½•å®Œæˆ")
    except Exception as e:
        print(f"âŒ è½¬å½•å¤±è´¥: {e}")
        return
    
    # 4. ä¿å­˜ç»“æœ
    output_file = "pyannote_whisper_complete.txt"
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write("=== Pyannote + Whisper å®Œæ•´è½¬å½•ç»“æœ ===\n\n")
        f.write("ä½¿ç”¨æ¨¡å‹:\n")
        f.write("- Pyannote: pyannote/speaker-diarization\n")
        f.write("- Whisper: small\n\n")
        
        for result in results:
            f.write(f"[{result['start']:.1f}s - {result['end']:.1f}s] {result['speaker']}: {result['text']}\n")
    
    print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
    
    # æ˜¾ç¤ºç»“æœé¢„è§ˆ
    print("\nğŸ“‹ è½¬å½•ç»“æœé¢„è§ˆ:")
    print("-" * 40)
    for result in results[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ªç‰‡æ®µ
        print(f"[{result['start']:.1f}s - {result['end']:.1f}s] {result['speaker']}: {result['text']}")

if __name__ == "__main__":
    main()
