#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
éŸ³é¢‘è½¬å½•æµ‹è¯•è„šæœ¬
ä½¿ç”¨Whisperè½¬å½•æŒ‡å®šçš„éŸ³é¢‘æ–‡ä»¶
"""

import whisper
import time
import os

def transcribe_audio_file(audio_path, model_name="tiny"):
    """
    è½¬å½•éŸ³é¢‘æ–‡ä»¶
    
    Args:
        audio_path (str): éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        model_name (str): æ¨¡å‹åç§° (tiny, base, small)
    """
    print(f"ğŸµ å¼€å§‹è½¬å½•éŸ³é¢‘æ–‡ä»¶: {audio_path}")
    print(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {model_name}")
    print("=" * 50)
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(audio_path):
        print(f"âŒ éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_path}")
        return None
    
    try:
        # 1. åŠ è½½æ¨¡å‹
        print(f"ğŸ”„ æ­£åœ¨åŠ è½½ {model_name} æ¨¡å‹...")
        start_load = time.time()
        model = whisper.load_model(model_name)
        load_time = time.time() - start_load
        print(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆï¼Œè€—æ—¶: {load_time:.2f}ç§’")
        
        # 2. æ‰§è¡Œè½¬å½•
        print(f"ğŸ“ å¼€å§‹è½¬å½•...")
        start_transcribe = time.time()
        result = model.transcribe(audio_path)
        transcribe_time = time.time() - start_transcribe
        
        print(f"âœ… è½¬å½•å®Œæˆï¼Œè€—æ—¶: {transcribe_time:.2f}ç§’")
        
        # 3. æ˜¾ç¤ºç»“æœ
        print(f"\nğŸ“‹ è½¬å½•ç»“æœ:")
        print("-" * 30)
        print(f"æ£€æµ‹è¯­è¨€: {result.get('language', 'æœªçŸ¥')}")
        print(f"è¯­è¨€æ¦‚ç‡: {result.get('language_probability', 'æœªçŸ¥')}")
        print(f"è½¬å½•æ–‡æœ¬: {result['text']}")
        
        # 4. æ˜¾ç¤ºè¯¦ç»†æ—¶é—´æˆ³ï¼ˆå¦‚æœæœ‰ï¼‰
        if 'segments' in result and result['segments']:
            print(f"\nâ° è¯¦ç»†æ—¶é—´æˆ³:")
            for segment in result['segments']:
                start = segment['start']
                end = segment['end']
                text = segment['text'].strip()
                print(f"[{start:.2f}s - {end:.2f}s] {text}")
        
        # 5. ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
        output_file = f"transcription_{model_name}.txt"
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(f"=== Whisperè½¬å½•ç»“æœ ===\n")
            f.write(f"éŸ³é¢‘æ–‡ä»¶: {audio_path}\n")
            f.write(f"ä½¿ç”¨æ¨¡å‹: {model_name}\n")
            f.write(f"æ£€æµ‹è¯­è¨€: {result.get('language', 'æœªçŸ¥')}\n")
            f.write(f"è¯­è¨€æ¦‚ç‡: {result.get('language_probability', 'æœªçŸ¥')}\n")
            f.write(f"è½¬å½•æ—¶é—´: {transcribe_time:.2f}ç§’\n\n")
            f.write("è½¬å½•æ–‡æœ¬:\n")
            f.write(result['text'])
            
            if 'segments' in result and result['segments']:
                f.write("\n\nè¯¦ç»†æ—¶é—´æˆ³:\n")
                for segment in result['segments']:
                    start = segment['start']
                    end = segment['end']
                    text = segment['text']
                    f.write(f"[{start:.2f}s - {end:.2f}s] {text}\n")
        
        print(f"\nğŸ’¾ è½¬å½•ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
        
        return result
        
    except Exception as e:
        print(f"âŒ è½¬å½•å¤±è´¥: {e}")
        return None

def compare_models(audio_path):
    """æ¯”è¾ƒä¸åŒæ¨¡å‹çš„è½¬å½•æ•ˆæœ"""
    print(f"ğŸ” æ¨¡å‹å¯¹æ¯”æµ‹è¯•")
    print(f"éŸ³é¢‘æ–‡ä»¶: {audio_path}")
    print("=" * 50)
    
    models_to_test = ["tiny", "base", "small"]
    results = {}
    
    for model_name in models_to_test:
        print(f"\nğŸ”„ æµ‹è¯• {model_name} æ¨¡å‹...")
        result = transcribe_audio_file(audio_path, model_name)
        if result:
            results[model_name] = result
    
    # æ˜¾ç¤ºå¯¹æ¯”ç»“æœ
    if results:
        print(f"\nğŸ“Š æ¨¡å‹å¯¹æ¯”æ€»ç»“:")
        print("-" * 50)
        for model_name, result in results.items():
            print(f"\n{model_name.upper()} æ¨¡å‹:")
            print(f"  è¯­è¨€: {result.get('language', 'æœªçŸ¥')}")
            print(f"  æ–‡æœ¬: {result['text'][:100]}{'...' if len(result['text']) > 100 else ''}")

def main():
    """ä¸»å‡½æ•°"""
    # ä½¿ç”¨æ‚¨æä¾›çš„éŸ³é¢‘æ–‡ä»¶
    audio_file = "ba84462e-fdee-42fe-9439-86808b3d3212.wav"
    
    print("ğŸš€ WhisperéŸ³é¢‘è½¬å½•æµ‹è¯•")
    print("=" * 50)
    
    # æ£€æŸ¥æ–‡ä»¶
    if not os.path.exists(audio_file):
        print(f"âŒ éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_file}")
        print("è¯·ç¡®ä¿éŸ³é¢‘æ–‡ä»¶åœ¨å½“å‰ç›®å½•ä¸­")
        return
    
    print(f"âœ… æ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶: {audio_file}")
    
    # é€‰æ‹©æµ‹è¯•æ¨¡å¼
    print("\nè¯·é€‰æ‹©æµ‹è¯•æ¨¡å¼:")
    print("1. å•ä¸ªæ¨¡å‹æµ‹è¯• (tiny)")
    print("2. æ¨¡å‹å¯¹æ¯”æµ‹è¯• (tiny, base, small)")
    
    choice = input("è¯·è¾“å…¥é€‰æ‹© (1 æˆ– 2): ").strip()
    
    if choice == "1":
        # å•ä¸ªæ¨¡å‹æµ‹è¯•
        transcribe_audio_file(audio_file, "tiny")
    elif choice == "2":
        # æ¨¡å‹å¯¹æ¯”æµ‹è¯•
        compare_models(audio_file)
    else:
        print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œä½¿ç”¨é»˜è®¤æ¨¡å¼")
        transcribe_audio_file(audio_file, "tiny")

if __name__ == "__main__":
    main() 