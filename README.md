# VoiceRecognize - è¯­éŸ³è¯†åˆ«é¡¹ç›®

è¿™æ˜¯ä¸€ä¸ªåŸºäºOpenAI Whisperå’ŒPyannote.audioçš„è¯­éŸ³è¯†åˆ«é¡¹ç›®ï¼Œæ”¯æŒå¤šè¯­è¨€è¯­éŸ³è½¬å½•å’Œè¯´è¯äººåˆ†ç¦»ã€‚

## åŠŸèƒ½ç‰¹æ€§

- ğŸ¤ **è¯­éŸ³è½¬å½•**: ä½¿ç”¨OpenAI Whisperè¿›è¡Œé«˜ç²¾åº¦è¯­éŸ³è½¬æ–‡æœ¬
- ğŸ‘¥ **è¯´è¯äººåˆ†ç¦»**: ä½¿ç”¨Pyannote.audioè¯†åˆ«ä¸åŒè¯´è¯äºº
- ğŸŒ **å¤šè¯­è¨€æ”¯æŒ**: æ”¯æŒä¸­æ–‡ã€è‹±æ–‡ç­‰å¤šç§è¯­è¨€
- âš¡ **æœ¬åœ°è¿è¡Œ**: å®Œå…¨æœ¬åœ°åŒ–ï¼Œæ— éœ€äº‘ç«¯æœåŠ¡
- ğŸ“Š **è¯¦ç»†åˆ†æ**: æä¾›è½¬å½•æ—¶é—´ã€è¯´è¯äººç»Ÿè®¡ç­‰è¯¦ç»†ä¿¡æ¯

## é¡¹ç›®ç»“æ„

```
voicerecognize/
â”œâ”€â”€ README.md                    # é¡¹ç›®è¯´æ˜
â”œâ”€â”€ .gitignore                   # Gitå¿½ç•¥æ–‡ä»¶
â”œâ”€â”€ requirements.txt             # Pythonä¾èµ–
â”œâ”€â”€ whisper_test.py             # Whisperç¯å¢ƒæµ‹è¯•
â”œâ”€â”€ whisper_example.py          # Whisperä½¿ç”¨ç¤ºä¾‹
â”œâ”€â”€ whisper_simple_test.py      # ç®€å•Whisperæµ‹è¯•
â”œâ”€â”€ whisper_pyannote_real.py    # Whisper + Pyannoteå®Œæ•´å®ç°
â”œâ”€â”€ whisper_with_simple_diarization.py  # ç®€åŒ–è¯´è¯äººåˆ†ç¦»æ¼”ç¤º
â”œâ”€â”€ transcribe_test.py          # è½¬å½•æµ‹è¯•è„šæœ¬
â”œâ”€â”€ demo_whisper.py             # Whisperæ¼”ç¤ºè„šæœ¬
â”œâ”€â”€ quick_test.py               # å¿«é€Ÿæµ‹è¯•è„šæœ¬
â”œâ”€â”€ README_whisper.md           # Whisperè¯¦ç»†è¯´æ˜
â”œâ”€â”€ real_vs_demo_comparison.md  # çœŸå®ç»“æœä¸æ¼”ç¤ºå¯¹æ¯”
â””â”€â”€ FireRedASR/                 # FireRedASRç›¸å…³æ–‡ä»¶
    â”œâ”€â”€ test_fireredasr.py
    â”œâ”€â”€ test_with_audio.py
    â”œâ”€â”€ long_audio_processor.py
    â”œâ”€â”€ test_fireredasr_official.py
    â”œâ”€â”€ test_single_segment.py
    â””â”€â”€ final_comparison_report.md
```

## ç¯å¢ƒè¦æ±‚

- Python 3.8-3.11
- FFmpeg
- PyTorch
- OpenAI Whisper
- Pyannote.audio (å¯é€‰ï¼Œç”¨äºè¯´è¯äººåˆ†ç¦»)

## å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒè®¾ç½®

```bash
# åˆ›å»ºcondaç¯å¢ƒ
conda create -n whisper python=3.11
conda activate whisper

# å®‰è£…FFmpeg
conda install -c conda-forge ffmpeg

# å®‰è£…ä¾èµ–
pip install -U openai-whisper
pip install "numpy<2"
pip install psutil
pip install pyannote.audio  # å¯é€‰ï¼Œç”¨äºè¯´è¯äººåˆ†ç¦»
```

### 2. åŸºæœ¬ä½¿ç”¨

```bash
# æµ‹è¯•ç¯å¢ƒ
python whisper_test.py

# ç®€å•è½¬å½•
python whisper_simple_test.py

# å®Œæ•´Whisper + Pyannote (éœ€è¦HF_TOKEN)
export HF_TOKEN="your_token_here"
python whisper_pyannote_real.py
```

## æ¨¡å‹è¯´æ˜

### Whisperæ¨¡å‹
- **tiny**: æœ€å¿«ï¼Œé€‚åˆå®æ—¶åº”ç”¨
- **base**: å¹³è¡¡é€Ÿåº¦å’Œå‡†ç¡®æ€§
- **small**: æ¨èä½¿ç”¨ï¼Œå‡†ç¡®æ€§å¥½
- **medium**: æ›´é«˜å‡†ç¡®æ€§ï¼Œä½†è¾ƒæ…¢
- **large**: æœ€é«˜å‡†ç¡®æ€§ï¼Œä½†éœ€è¦æ›´å¤šèµ„æº

### Pyannoteæ¨¡å‹
- **speaker-diarization-3.1**: è¯´è¯äººåˆ†ç¦»æ¨¡å‹
- **segmentation-3.0**: è¯­éŸ³åˆ†å‰²æ¨¡å‹

## ä½¿ç”¨ç¤ºä¾‹

### åŸºæœ¬è½¬å½•
```python
import whisper

# åŠ è½½æ¨¡å‹
model = whisper.load_model("small")

# è½¬å½•éŸ³é¢‘
result = model.transcribe("audio.wav")
print(result["text"])
```

### è¯´è¯äººåˆ†ç¦» + è½¬å½•
```python
from pyannote.audio import Pipeline
import whisper

# åˆå§‹åŒ–Pipeline
pipeline = Pipeline.from_pretrained(
    "pyannote/speaker-diarization-3.1",
    use_auth_token="your_token"
)

# è¯´è¯äººåˆ†ç¦»
diarization = pipeline("audio.wav")

# å¯¹æ¯ä¸ªç‰‡æ®µè¿›è¡Œè½¬å½•
whisper_model = whisper.load_model("small")
for turn, _, speaker in diarization.itertracks(yield_label=True):
    # æå–éŸ³é¢‘ç‰‡æ®µå¹¶è½¬å½•
    # ...
```

## æµ‹è¯•ç»“æœ

é¡¹ç›®åŒ…å«å¤šä¸ªæµ‹è¯•è„šæœ¬å’Œç»“æœæ–‡ä»¶ï¼š
- `whisper_simple_result.txt`: Whisperè½¬å½•ç»“æœ
- `whisper_pyannote_real_result.txt`: å®Œæ•´è½¬å½•ç»“æœ
- `real_vs_demo_comparison.md`: ç»“æœåˆ†æ

## æ³¨æ„äº‹é¡¹

1. **æ¨¡å‹æ–‡ä»¶**: é¦–æ¬¡è¿è¡Œä¼šè‡ªåŠ¨ä¸‹è½½æ¨¡å‹æ–‡ä»¶ï¼Œéœ€è¦ç½‘ç»œè¿æ¥
2. **HF_TOKEN**: ä½¿ç”¨Pyannoteéœ€è¦HuggingFaceè®¿é—®ä»¤ç‰Œ
3. **å†…å­˜è¦æ±‚**: å¤§æ¨¡å‹éœ€è¦è¾ƒå¤šå†…å­˜å’ŒGPUèµ„æº
4. **éŸ³é¢‘æ ¼å¼**: æ”¯æŒå¸¸è§éŸ³é¢‘æ ¼å¼ï¼Œå»ºè®®ä½¿ç”¨WAVæ ¼å¼

## è®¸å¯è¯

æœ¬é¡¹ç›®åŸºäºMITè®¸å¯è¯å¼€æºã€‚

## è´¡çŒ®

æ¬¢è¿æäº¤Issueå’ŒPull Requestæ¥æ”¹è¿›é¡¹ç›®ï¼ 